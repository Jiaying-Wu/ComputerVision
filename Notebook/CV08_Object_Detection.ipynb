{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6321213e",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Datasets-for-Object-Detection\" data-toc-modified-id=\"Datasets-for-Object-Detection-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Datasets for Object Detection</a></span><ul class=\"toc-item\"><li><span><a href=\"#PASCAL-VOC-Dataset\" data-toc-modified-id=\"PASCAL-VOC-Dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>PASCAL VOC Dataset</a></span></li><li><span><a href=\"#COCO-Dataset\" data-toc-modified-id=\"COCO-Dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>COCO Dataset</a></span></li></ul></li><li><span><a href=\"#Single-Object-vs-Multiple-Objects\" data-toc-modified-id=\"Single-Object-vs-Multiple-Objects-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Single Object vs Multiple Objects</a></span></li><li><span><a href=\"#Regions-Proposals\" data-toc-modified-id=\"Regions-Proposals-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Regions Proposals</a></span></li><li><span><a href=\"#R-CNN\" data-toc-modified-id=\"R-CNN-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>R-CNN</a></span></li><li><span><a href=\"#Fast-R-CNN\" data-toc-modified-id=\"Fast-R-CNN-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Fast R-CNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#ROI-Pooling\" data-toc-modified-id=\"ROI-Pooling-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>ROI Pooling</a></span></li><li><span><a href=\"#Fast-R-CNN-vs-R-CNN\" data-toc-modified-id=\"Fast-R-CNN-vs-R-CNN-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Fast R-CNN vs R-CNN</a></span></li></ul></li><li><span><a href=\"#Faster-RCNN\" data-toc-modified-id=\"Faster-RCNN-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Faster RCNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Region-Proposal-Network\" data-toc-modified-id=\"Region-Proposal-Network-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Region Proposal Network</a></span></li><li><span><a href=\"#Fast-R-CNN-vs-Faster-R-CNN\" data-toc-modified-id=\"Fast-R-CNN-vs-Faster-R-CNN-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Fast R-CNN vs Faster R-CNN</a></span></li></ul></li><li><span><a href=\"#YOLO\" data-toc-modified-id=\"YOLO-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>YOLO</a></span><ul class=\"toc-item\"><li><span><a href=\"#YOLO-vs.-Faster-R-CNN\" data-toc-modified-id=\"YOLO-vs.-Faster-R-CNN-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>YOLO vs. Faster R-CNN</a></span></li></ul></li><li><span><a href=\"#How-to-preidction-to-ground-truth-box?\" data-toc-modified-id=\"How-to-preidction-to-ground-truth-box?-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>How to preidction to ground-truth box?</a></span></li><li><span><a href=\"#Overlappng-Boxes\" data-toc-modified-id=\"Overlappng-Boxes-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Overlappng Boxes</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca332d",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "- Input: image\n",
    "\n",
    "- Output: object bounding boxes and class labels\n",
    "\n",
    "- Datasets:\n",
    "\n",
    "    - Pascal VOC\n",
    "\n",
    "    - MS-COCO \n",
    "    \n",
    "    - ...\n",
    "\n",
    "![](image/cv_object_detection.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5cc9e",
   "metadata": {},
   "source": [
    "## Datasets for Object Detection\n",
    "\n",
    "### PASCAL VOC Dataset\n",
    "\n",
    "website: http://host.robots.ox.ac.uk/pascal/VOC/\n",
    "\n",
    "- 20 challenge classes:\n",
    "\n",
    "    - Person\n",
    "    \n",
    "    - Animals: bird, cat, cow, dog, horse, sheep\n",
    "\n",
    "    - Vehicles: airplane, bicycle, boat, bus, car, motorbike, train\n",
    "\n",
    "    - Indoor: bottle, chair, dining table, potted plant, sofa, tv/monitor\n",
    "\n",
    "- Dataset size (by 2012): 11.5K training/validation images, 27K bounding boxes, 7K segmentations\n",
    "\n",
    "![](image/cv_PASCAL_VOC.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccedb211",
   "metadata": {},
   "source": [
    "### COCO Dataset\n",
    "\n",
    "website: http://cocodataset.org/#home\n",
    "\n",
    "![](image/cv_coco.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b8176d",
   "metadata": {},
   "source": [
    "## Single Object vs Multiple Objects\n",
    "\n",
    "![](image/cv_single_object_detection.png)\n",
    "\n",
    "\n",
    "![](image/cv_multi_object_detection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe8c60",
   "metadata": {},
   "source": [
    "## Regions Proposals\n",
    "\n",
    "![](image/cv_ROI.png)\n",
    "\n",
    "**Selective search for detection**\n",
    "\n",
    "paper: (J. Uijlings, K. van de Sande, T. Gevers, and A. Smeulders, Selective Search for Object Recognition, IJCV 2013)\n",
    "\n",
    "• Use hierarchical segmentation: start with small superpixels and merge based on diverse cues\n",
    "\n",
    "![](image/cv_selective_search.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b1d94",
   "metadata": {},
   "source": [
    "## R-CNN\n",
    "\n",
    "paper: (R. Girshick et al. CVPR’14)\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- Much more accurate than previous approaches!\n",
    "\n",
    "- Any deep architecture can immediately be “plugged in”\n",
    "\n",
    "- **Cons**\n",
    "\n",
    "- Not a single end-to-end system\n",
    "\n",
    "    - Fine-tune network with softmax classifier (log loss)\n",
    "    \n",
    "    - Train post-hoc linear SVMs (hinge loss)\n",
    "    \n",
    "    - Train post-hoc bounding-box regressions (least squares)\n",
    "\n",
    "- Training was slow (84h), took up a lot of storage\n",
    "\n",
    "    - 2000 CNN passes per image\n",
    "\n",
    "- Inference (detection) was slow (47s / image with VGG16)\n",
    "\n",
    "![](image/cv_rcnn_1.png)\n",
    "\n",
    "![](image/cv_rcnn_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b8e467",
   "metadata": {},
   "source": [
    "## Fast R-CNN\n",
    "\n",
    "paper: (Source: R. Girshick, Fast R-CNN, ICCV 2015)\n",
    "\n",
    "![](image/cv_fast_rcnn_1.png)\n",
    "\n",
    "![](image/cv_fast_rcnn_2.png)\n",
    "\n",
    "### ROI Pooling\n",
    "\n",
    "![](image/cv_fast_rcnn_roi_pooling.png)\n",
    "\n",
    "![](image/cv_fast_rcnn_roi_pooling_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96956d",
   "metadata": {},
   "source": [
    "### Fast R-CNN vs R-CNN\n",
    "\n",
    "![](image/cv_rcnn_vs_fast_rcnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02c82a",
   "metadata": {},
   "source": [
    "## Faster RCNN\n",
    "\n",
    "papers:\n",
    "\n",
    "- S. Ren, K. He, R. Girshick, and J. Sun, “Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks”, NIPS 2015\n",
    "\n",
    "-  S. Ren, K. He, R. Girshick, and J. Sun, “Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks”, TPAMI 2016\n",
    "\n",
    "![](image/cv_faster_rcnn.png)\n",
    "\n",
    "![](image/cv_faster_rcnn_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fd8585",
   "metadata": {},
   "source": [
    "### Region Proposal Network\n",
    "\n",
    "- For each point of the Feature map, propose K different anchor boxes of different size.\n",
    "\n",
    "- Then at each point predict wether the anchor boxes contain an object.\n",
    "\n",
    "- Sort all anchor boxes base on their objectness score, take top ~300 as our proposals.\n",
    "\n",
    "![](image/cv_Region_Proposal_Network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21046658",
   "metadata": {},
   "source": [
    "### Fast R-CNN vs Faster R-CNN\n",
    "\n",
    "![](image/cv_fast_rcnn_vs_faster_rcnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c91964b",
   "metadata": {},
   "source": [
    "## YOLO\n",
    "\n",
    "papers:\n",
    "\n",
    "- J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You Only Look Once: Unified, Real-Time Object Detection”, CVPR 2016\n",
    "\n",
    "- W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, and A. Berg, “SSD: Single Shot MultiBox Detector”, ECCV 2016\n",
    "\n",
    "![](image/cv_yolo_1.png)\n",
    "\n",
    "**How it work?**\n",
    "\n",
    "1. Take conv feature maps at 7x7 resolution\n",
    "\n",
    "2. Add two FC layers to predict, at each location, a score for each class and 2 bboxes w/ confidences\n",
    "\n",
    "    - For PASCAL, output is 7 × 7 × 30 (30 = 20 + 2 ∗ (4 + 1))\n",
    "\n",
    "![](image/cv_yolo.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98b3dd",
   "metadata": {},
   "source": [
    "### YOLO vs. Faster R-CNN\n",
    "\n",
    "![](image/cv_yolo_vs_faster_rcnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed85a603",
   "metadata": {},
   "source": [
    "## How to preidction to ground-truth box?\n",
    "\n",
    "![](image/cv_iou.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b85010",
   "metadata": {},
   "source": [
    "## Overlappng Boxes\n",
    "\n",
    "![](image/cv_overlapping_boxes.png)\n",
    "\n",
    "![](image/cv_nms_boxes.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
